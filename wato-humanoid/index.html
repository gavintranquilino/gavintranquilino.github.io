<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>WATonomous Humanoid Robotics | Gavin Tranquilino</title>
<link rel=icon href=/img/smile-round.svg><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css integrity="sha512-HK5fgLBL+xu6dm/Ii3z4xhlSUyZgTT9tuc/hSrtw6uzJOvgRr2a9jyxxT1ely+B+xFAmJKVSTbpM/CuL7qxO8w==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/devicons/devicon@v2.15.1/devicon.min.css><meta property="og:url" content="https://www.gavintranquilino.com/wato-humanoid/"><meta property="og:type" content="article"><meta property="og:title" content="WATonomous <strong>Humanoid Robotics</strong>"><meta property="og:description" content="Currently in Development I am currently working on a humanoid robot arm project with the University of Waterloo&rsquo;s design teams, WATonomous and UW Reality Labs. The goal is to create an anthropomorphic humanoid robot arm that can perform a variety of tasks with dexterity and precision.
The CURRENT focus is on creating a V1 prototype with full hardware. This includes the mechanical design, power electronics, embedded software, and control algorithms. The V1 prototype will be capable of teleoperated control via Quest 3 Headsets&rsquo; hand tracking through a custom Unity application built by the UW Reality Labs team."><meta property="og:image" content="https://www.gavintranquilino.com/wato-humanoid/thumbs-up.gif"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,900|Source+Sans+Pro:300,900&display=swap"><link rel=stylesheet href=/css/style.css></head><body><header><div class=logo></div><button class=nav-toggle aria-label="toggle navigation">
<span class=hamburger></span>
</button>
<button class=theme-toggle aria-label="toggle theme">
<span class=sun-moon><i class="fas fa-cloud-sun"></i></span>
</button>
<button onclick=topFunction() class=to-top>
<span class=up-arrow></span></button><nav class=nav><ul class=nav__list><li class=nav__item><a href=/#home class=nav__link>Home</a></li><li class=nav__item><a href=/#about class=nav__link>About Me</a></li><li class=nav__item><a href=/#work class=nav__link>My Work</a></li></ul></nav></header><main id=main-content><section class=intro><h1 class="section__title section__title--intro">WATonomous <strong>Humanoid Robotics</strong></h1><p class="section__subtitle section__subtitle--intro">6DoF robotic arms with 20DoF anthropomorphic hands</p><img src=/img/wato-humanoid/thumbs-up_hu98936e77ef07f34213fb5b45394216c9_765071_800x0_resize_q85_box_1.gif alt="WATonomous <strong>Humanoid Robotics</strong> main image" class=intro__img loading=lazy></section><article class=project-content><h2 id=currently-in-development>Currently in Development</h2><p>I am currently working on a humanoid robot arm project with the University of Waterloo&rsquo;s design teams, <em>WATonomous</em> and <em>UW Reality Labs</em>. The goal is to create an <strong>anthropomorphic humanoid robot arm</strong> that can perform a variety of tasks with dexterity and precision.</p><p>The <em>CURRENT</em> focus is on creating a V1 prototype with full hardware. This includes the mechanical design, power electronics, embedded software, and control algorithms. The V1 prototype will be capable of teleoperated control via Quest 3 Headsets&rsquo; hand tracking through a custom Unity application built by the UW Reality Labs team.</p><p>The <em>ULTIMATE</em> goal is to train the humanoid arm to perform tasks automatically using reinforcement learning. This will involve developing a robust simulation environment using NVIDIA&rsquo;s Isaac Sim. The main objective is to get the humanoid arms to learn to <strong>autonomously type on a keyboard</strong>, which requires precise finger movements and coordination. <em>(It would also look really cool since now LLMs can interact with my physical keyboard and edit code directly!)</em></p><br><h2 id=my-role>My Role</h2><p>I am a Co-op student for the WATonomous team during the Winter 2025 term, and I am responsible for several key aspects of the humanoid arm project:</p><h3 id=mounting-a-canbus-transceiver-in-docker>Mounting a CANbus Transceiver in Docker</h3><p>I am responsible for the interfacing between the hardware and software components of the humanoid arm. This includes developing the CAN bus communication protocols, integrating the sensors and actuators, and ensuring smooth data flow between the different systems. An interfacing ROS2 (Robot Operating System 2) C++ node is being developed to mount a USB2CAN transceiver to send and receive messages using a CANable 2.0 device.</p><div class="iframe-container landscape"><iframe src=https://www.youtube.com/embed/qJ9y6icVFc8 title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen referrerpolicy=strict-origin-when-cross-origin></iframe></div><p>I am mounting the CANable 2.0 device in a Docker container to allow communication through ROS2 topics and services over a CAN bus. This setup requires configuration of the Docker container to recognize the CANable device, which is done by adding the device with a Linux symlink to the /dev/canable interface. The Dockerfile includes the necessary dependencies and configurations to ensure that the ROS2 node can communicate with the CAN bus effectively.</p><p>Read further below for more details on the <a href=#interfacing-system-documentation>interfacing system documentation</a>.</p><h3 id=urdf-simulation-in-nvidia-isaac-sim>URDF Simulation in NVIDIA Isaac Sim</h3><p>I am also working on the simulation URDF (Unified Robot Description Format) for the humanoid arm in NVIDIA&rsquo;s Isaac Sim. This will allow us to test and refine the control algorithms in a virtual environment before deploying them on the physical robot. Within the URDF, I am also implementing the hardware IDs of all the motors and sensors, which is crucial for the CAN bus communication.</p><p>I first created a URDF file for the humanoid arm, which includes the kinematic and dynamic properties of the robot by using an open source Fusion360 script to export the model called fusion2urdf. This script generates a URDF file from the Fusion360 model, which can then be imported into Isaac Sim for simulation.</p><p>Here is my motion study of the humanoid arm to visualize the dynamics of the arm to gesture a thumbs up:</p><div class="iframe-container landscape"><iframe src=https://www.youtube.com/embed/csXZSvSeIx4 title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen referrerpolicy=strict-origin-when-cross-origin></iframe></div><h3 id=interfacing-system-documentation>Interfacing System Documentation</h3><p>Below is my documentation for the interfacing system, which includes the CAN bus communication protocols, ROS2 package structure, and how to set up the CANable device in a Docker container.</p><h4 id=communication-protocols>Communication Protocols</h4><ul><li><a href=https://uwaterloo.atlassian.net/wiki/spaces/UWRT/pages/33929856904/Intro+to+Communication+Protocols>Intro to Communication Protocols (UWRT)</a><ul><li>Comparisons between protocols</li></ul></li></ul><h3 id=can-package>CAN Package</h3><p><em>Goal</em>: Implement a ROS 2 package to bridge communication between a high-level controller and an embedded hand system via CAN bus. The package will:</p><ol><li>Receive ROS 2 movement messages from the controller/behaviour node.</li><li>Convert and send these messages as CAN frames through a USB transceiver (accessible within a Docker container).</li><li>Receive CAN frames from the embedded system containing hand odometry</li><li>Convert and publish this odometry as ROS 2 messages for feedback to the controller.</li></ol><ul><li>Location on the repository: <a href=https://github.com/WATonomous/humanoid/tree/interfacing/autonomy/interfacing/can>humanoid/autonomy/interfacing/can</a></li></ul><h5 id=persistent-device-mount-for-canable-usb-device-in-docker>Persistent Device Mount for CANable USB Device in Docker</h5><p>Ensure that the CANable USB device is always mounted to /dev/canable on the <em>host system</em>, making it easy to reference consistently in Docker containers.</p><p>The host system is responsible for setting up a symlink to <code>/dev/canable</code> , and the docker compose accesses the host’s symlink</p><p><img src=/img/wato-humanoid/image.png alt=image.png loading=lazy></p><ul><li><p><strong>How to setup the host system to mount the CANable 2.0 device to /dev/canable using symbolic links (symlinks)</strong></p><ul><li><strong>Purpose:</strong> ensure that the CANable device always mounts to the same port under <code>/dev/canable</code></li><li>Good to know terminology:<ul><li><strong>Symlink</strong>: file that points to other files/directories on the machine</li><li><strong>udev</strong> - device manager for Linux kernel responsible for managing nodes in the <code>/dev</code> directory</li><li>The CAN transceivers all have serial numbers that are constant to the device</li></ul></li></ul><ol><li><p>Find the /dev/ttyACMx port that the CANable 2.0 device mounts onto, where is a number</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls /dev/ttyACM*
</span></span></code></pre></div></li><li><p>Find the serial number of the CANable device</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>udevadm info -a -n /dev/ttyACMx | grep -m <span style=color:#ae81ff>1</span> serial
</span></span></code></pre></div></li><li><p>Create a custom rule to make a persistent symlink, and ensure the correct serial value</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>echo <span style=color:#e6db74>&#39;SUBSYSTEM==&#34;tty&#34;, ATTRS{idVendor}==&#34;16d0&#34;, ATTRS{idProduct}==&#34;117e&#34;, ATTRS{serial}==&#34;208B38B43136&#34;, SYMLINK+=&#34;canable&#34;&#39;</span> | sudo tee /etc/udev/rules.d/99-canable.rules
</span></span></code></pre></div></li><li><p>Reload udev Rules and Trigger</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo udevadm control --reload-rules
</span></span><span style=display:flex><span>sudo udevadm trigger
</span></span></code></pre></div></li><li><p>Verify the new symlink</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ls -l /dev/canable
</span></span></code></pre></div><p>Should point to <code>/dev/tty/ACMx</code></p></li></ol></li><li><p>On startup, the interfacing docker container will always mount onto the host’s port called <code>/dev/canable/</code></p><ul><li><strong>file: <code>interfacing.Dockerfile</code></strong><ul><li><code>ENV UDEV=1</code><ul><li>required to pass the host machine’s udev symlinks to the container</li></ul></li></ul></li><li><strong>file: <code>docker-compose.interfacing.yaml</code></strong><ul><li><code>privileged: false</code><ul><li>setting to true bypasses the symbolic link that the host set</li></ul></li><li><code>devices: /dev/canable:/dev/canable</code><ul><li>mount the host’s canable port to container’s canable port</li></ul></li><li><code>network_mode: host</code><ul><li>allow the container to access the host’s network interfaces</li></ul></li><li><code>cap_add: NET_ADMIN</code><ul><li>Grant capability to configure network interfaces</li></ul></li></ul></li></ul></li></ul><h5 id=initializing-the-canable-as-a-can-bus-master-in-code>Initializing the CANable as a CAN Bus “Master” in Code</h5><p>Set the CAN Bus speeds, message length, and queue length of CAN messages on the host’s CAN transceiver in a C++ ROS2 package in the “interfacing” directory in the autonomy</p><ul><li><a href=https://github.com/linux-can/can-utils>https://github.com/linux-can/can-utils</a></li></ul><h5 id=setup-can-device-parameters-on-can0-by-running-slcan-daemon>Setup CAN device parameters on <code>can0</code> by running SLCAN Daemon</h5><p>Run a bash script to call the <code>slcand</code> tool from <code>can-utils</code> to setup the bus speed, interface name, etc.</p><ul><li>“slcand : daemon for serial line CAN interface configuration”<ul><li><a href="https://github.com/linux-can/can-utils?tab=readme-ov-file#serial-line-discipline-configuration-for-slcan-driver">https://github.com/linux-can/can-utils?tab=readme-ov-file#serial-line-discipline-configuration-for-slcan-driver</a></li><li><strong>Daemon process</strong> that runs continuously in the background</li><li>Handles both configuration and ongoing management</li><li>Creates the interface and keeps it running</li><li>This one command does everything</li></ul></li><li>The script for the can setup can be found in <code>can/scripts/setup_can.sh</code><ul><li>Uses parameters from the <code>config/params.yml</code> to setup the CAN interface</li></ul></li></ul><h5 id=how-to-change-the-can-bus-parameterssettings>How to change the CAN bus parameters/settings</h5><ul><li><code>autonomy/interfacing/can/config/params.yml</code>
<img src=/img/wato-humanoid/image1.png alt=image.png loading=lazy><ul><li>After changing these values, you’d have to rebuild the container<ul><li><code>./watod build</code></li></ul></li></ul></li></ul><h5 id=ros2-api>ROS2 API</h5><ul><li><strong>Transmitting Data (ROS2 → CAN →Embedded)</strong><ul><li><strong>Role:</strong> ROS2-to-CAN Translator</li><li><strong>Process:</strong><ol><li>Subscribes to a configurable list of ROS2 topics</li><li>Receives any type of ROS2 message from these topics</li><li>Transmits the CAN frames over the bus to embedded devices<ol><li>Converts/serializes the message data into CAN frames</li></ol></li></ol></li><li><strong>Format Agnostic</strong><ul><li>doesn’t care about message structure, just forward raw ROS2 message data</li></ul></li></ul></li><li><strong>Receiving Data (Embedded → CAN → ROS2)</strong><ul><li><strong>Role:</strong> CAN-to-ROS2 Translator</li><li><strong>Process:</strong><ol><li>Listen for incoming CAN messages from embedded devices</li><li>Receives raw data packets from CAN bus</li><li>Convert CAN frames back into ROS2 messages</li><li>Publishes the data on appropriate ROS2 topics</li></ol></li></ul></li></ul><h4 id=sending-messages-from-subscribed-topics>Sending Messages from Subscribed Topics</h4><h5 id=creating-a-test-ros2-publisher-for-sample-finger-xyz-data>Creating a test ROS2 publisher for sample finger xyz data</h5><ul><li>changed topic name to <code>/test_controller</code></li></ul><p><img src=/img/wato-humanoid/image2.png alt=image.png loading=lazy></p><h5 id=preview>Preview</h5><video controls style=width:100%>
<source src=/img/wato-humanoid/screencast1.webm type=video/webm>Your browser does not support the video tag.</video><h4 id=ros2-package-structure-sending-messages>ROS2 Package Structure (Sending Messages)</h4><p><img src=/img/wato-humanoid/image3.png alt=image.png loading=lazy></p><h5 id=can-fd---intro>CAN FD - Intro</h5><ul><li>CAN FD uses the same differential pair structure of CAN 2.0, but with 2 different bit rates<ul><li><strong>Arbitration Phase (slow)</strong><ul><li>Who gets to talk</li><li>Always slow (500kbps for compatibility)</li><li>Contains: CAN ID, control bits, frame setup</li></ul></li><li><strong>Data Phase (fast)</strong><ul><li>The actual message</li><li>Bitrate determined by BRS (bit rate speed) bit from the Arbritration Phase</li><li>Contains: actual payload data + error checking</li></ul></li></ul></li></ul><p><strong>Classic CAN Frame:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>Time:  0μs    10μs   20μs   30μs   40μs   50μs
</span></span><span style=display:flex><span>       │      │      │      │      │      │
</span></span><span style=display:flex><span>Volt: ─┐    ┌─┐    ┌─┐    ┌─┐    ┌─┐    ┌─
</span></span><span style=display:flex><span>       └────┘ └────┘ └────┘ └────┘ └────┘
</span></span><span style=display:flex><span>       Start  ID     RTR    Data   CRC    EOF
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>All bits: 2μs duration <span style=color:#f92672>(</span><span style=color:#ae81ff>500</span> kbps<span style=color:#f92672>)</span>
</span></span></code></pre></div><p><strong>CAN FD Frame:</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>Time:  0μs    10μs   20μs   25μs   30μs   40μs
</span></span><span style=display:flex><span>       │      │      │      │      │      │
</span></span><span style=display:flex><span>Volt: ─┐    ┌─┐    ┌──┐┌┐┌┐┌─┐    ┌─────
</span></span><span style=display:flex><span>       └────┘ └────┘  └┘└┘└┘ └────┘
</span></span><span style=display:flex><span>       Start  ID     FDF  Fast Data  CRC
</span></span><span style=display:flex><span>                     BRS  <span style=color:#f92672>(</span>0.5μs bits<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Arbitration: 2μs per bit <span style=color:#f92672>(</span><span style=color:#ae81ff>500</span> kbps<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>Data phase:  0.5μs per bit <span style=color:#f92672>(</span><span style=color:#ae81ff>2</span> Mbps<span style=color:#f92672>)</span> ← 4x faster!
</span></span></code></pre></div></article></main><footer class=footer><a href=mailto:gtranqui@uwaterloo.ca class=footer__link>gtranqui@uwaterloo.ca</a><ul class=social-list><li class=social-list__item><a class=social-list__link href=https://linkedin.com/in/gavintranquilino/ target=_blank rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a></li><li class=social-list__item><a class=social-list__link href=https://github.com/gavintranquilino target=_blank rel="noopener noreferrer"><i class="fab fa-github"></i></a></li><li class=social-list__item><a class=social-list__link href=https://www.youtube.com/@gavintranquilino target=_blank rel="noopener noreferrer"><i class="fab fa-youtube"></i></a></li><li class=social-list__item><a class=social-list__link href=https://www.twitter.com/@gavintranqui target=_blank rel="noopener noreferrer"><i class="fab fa-twitter"></i></a></li><li class=social-list__item><a class=social-list__link href=https://discord.gg/cZKEPHugRt target=_blank rel="noopener noreferrer"><i class="fab fa-discord"></i></a></li><li class=social-list__item><a class=social-list__link href=https://devpost.com/gavintranquilino target=_blank rel="noopener noreferrer"><i class="fab fa-dev"></i></a></li><li class=social-list__item><a class=social-list__link href=https://stackoverflow.com/users/13495609/guhbean target=_blank rel="noopener noreferrer"><i class="fab fa-stack-overflow"></i></a></li><li class=social-list__item><a class=social-list__link href=https://www.instagram.com/gavin.tranq/ target=_blank rel="noopener noreferrer"><i class="fab fa-instagram"></i></a></li></ul></footer><script src=/js/index.js></script><script src=https://cdn.jsdelivr.net/npm/publicalbum@latest/embed-ui.min.js async></script></body></html>